{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SisFall Data Preprocessing Pipeline\n",
    "\n",
    "This notebook demonstrates the complete data preprocessing pipeline for the SisFall dataset, including:\n",
    "\n",
    "1.  Metadata extraction from filenames.\n",
    "2.  Subject-wise data splitting into training, validation, and test sets.\n",
    "3.  Loading raw sensor data and converting it to physical units (g and deg/s).\n",
    "4.  Normalization (Standardization) using training set statistics.\n",
    "5.  Segmentation of time-series data into overlapping windows.\n",
    "6.  Serialization of the processed data, scaler, and metadata for efficient future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data directory: /Users/minhphan/src/Fall-TSAD/data/SisFall/raw\n",
      "Processed data will be saved to: /Users/minhphan/src/Fall-TSAD/data/SisFall/processed\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary imports and set up paths\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add the src directory to the Python path to import custom modules\n",
    "if str(Path('../src').resolve()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path('../src').resolve()))\n",
    "\n",
    "from data.sisfall_paths import RAW_DATA_DIR, PROCESSED_DATA_DIR\n",
    "from data.sisfall_metadata import build_metadata\n",
    "from data.sisfall_split import split_data_by_subject\n",
    "from data.sisfall_loader import load_sisfall_file\n",
    "from data.sisfall_normalize import StandardScaler\n",
    "from data.sisfall_segment import segment_dataset\n",
    "from data.sisfall_serialize import save_processed_data, load_processed_data\n",
    "\n",
    "# Create processed data directory if it doesn't exist\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Raw data directory: {RAW_DATA_DIR}\")\n",
    "print(f\"Processed data will be saved to: {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 600  # 3 seconds at 200Hz\n",
    "OVERLAP = 300      # 50% overlap\n",
    "RANDOM_STATE = 42  # For reproducibility of subject split\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "# Test ratio will be 1 - TRAIN_RATIO - VAL_RATIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Metadata Extraction and Subject-wise Splitting\n",
    "\n",
    "First, we extract metadata from all raw data filenames and then split this metadata into training, validation, and test sets based on unique subjects. This ensures that data from any single subject appears in only one split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Building Metadata and Splitting by Subject ---\n",
      "Total files found: 4505\n",
      "Unique subjects: 38\n",
      "Train subjects: 26 (files: 3042)\n",
      "Validation subjects: 5 (files: 390)\n",
      "Test subjects: 7 (files: 1073)\n",
      "Example of training metadata:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>code</th>\n",
       "      <th>subject</th>\n",
       "      <th>group</th>\n",
       "      <th>trial</th>\n",
       "      <th>is_fall</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D01_SA01_R01.txt</td>\n",
       "      <td>D01</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D02_SA01_R01.txt</td>\n",
       "      <td>D02</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D03_SA01_R01.txt</td>\n",
       "      <td>D03</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D04_SA01_R01.txt</td>\n",
       "      <td>D04</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D05_SA01_R01.txt</td>\n",
       "      <td>D05</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename code subject  group trial  is_fall  \\\n",
       "0  D01_SA01_R01.txt  D01    SA01  Adult   R01        0   \n",
       "1  D02_SA01_R01.txt  D02    SA01  Adult   R01        0   \n",
       "2  D03_SA01_R01.txt  D03    SA01  Adult   R01        0   \n",
       "3  D04_SA01_R01.txt  D04    SA01  Adult   R01        0   \n",
       "4  D05_SA01_R01.txt  D05    SA01  Adult   R01        0   \n",
       "\n",
       "                                                path  \n",
       "0  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "1  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "2  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "3  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "4  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Step 1: Building Metadata and Splitting by Subject ---\")\n",
    "metadata_df = build_metadata(RAW_DATA_DIR)\n",
    "print(f\"Total files found: {len(metadata_df)}\")\n",
    "print(f\"Unique subjects: {metadata_df['subject'].nunique()}\")\n",
    "\n",
    "train_meta, val_meta, test_meta = split_data_by_subject(\n",
    "    metadata_df, \n",
    "    train_ratio=TRAIN_RATIO, \n",
    "    val_ratio=VAL_RATIO, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train subjects: {train_meta['subject'].nunique()} (files: {len(train_meta)})\")\n",
    "print(f\"Validation subjects: {val_meta['subject'].nunique()} (files: {len(val_meta)})\")\n",
    "print(f\"Test subjects: {test_meta['subject'].nunique()} (files: {len(test_meta)})\")\n",
    "\n",
    "print(\"Example of training metadata:\")\n",
    "display(train_meta.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data for Each Split with Unit Conversion\n",
    "\n",
    "Now, we iterate through the metadata for each split, load the corresponding raw data files, and apply the unit conversion (bits to g/deg/s) as defined in `sisfall_loader.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Loading Raw Data with Unit Conversion ---\n",
      "Loaded 3042 training data files.\n",
      "Loaded 390 validation data files.\n",
      "Loaded 1073 test data files.\n",
      "Example train data shape (first file): (19999, 6)\n",
      "Example train data (first 5 rows of first file):\n",
      "[[ 6.6406250e-02 -6.9921875e-01 -3.8671875e-01 -1.0986328e+00\n",
      "  -3.0761719e+01 -2.1484375e+01]\n",
      " [ 5.8593750e-02 -6.7968750e-01 -3.5156250e-01 -3.2348633e+00\n",
      "  -3.4667969e+01 -1.8676758e+01]\n",
      " [ 3.9062500e-03 -6.8750000e-01 -3.1640625e-01 -5.1269531e+00\n",
      "  -3.7414551e+01 -1.6540527e+01]\n",
      " [-3.9062500e-02 -7.0312500e-01 -3.0078125e-01 -6.3476562e+00\n",
      "  -3.9489746e+01 -1.3854980e+01]\n",
      " [-8.2031250e-02 -7.4609375e-01 -2.4609375e-01 -7.8125000e+00\n",
      "  -4.1198730e+01 -1.1657715e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 2: Loading Raw Data with Unit Conversion ---\")\n",
    "\n",
    "def load_data_for_split(meta_df: pd.DataFrame) -> list[np.ndarray]:\n",
    "    data_list = []\n",
    "    for idx, row in meta_df.iterrows():\n",
    "        file_path = Path(row['path'])\n",
    "        try:\n",
    "            data = load_sisfall_file(file_path)\n",
    "            data_list.append(data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {file_path} due to error: {e}\")\n",
    "    return data_list\n",
    "\n",
    "train_raw_data = load_data_for_split(train_meta)\n",
    "val_raw_data = load_data_for_split(val_meta)\n",
    "test_raw_data = load_data_for_split(test_meta)\n",
    "\n",
    "print(f\"Loaded {len(train_raw_data)} training data files.\")\n",
    "print(f\"Loaded {len(val_raw_data)} validation data files.\")\n",
    "print(f\"Loaded {len(test_raw_data)} test data files.\")\n",
    "\n",
    "if train_raw_data:\n",
    "    print(f\"Example train data shape (first file): {train_raw_data[0].shape}\")\n",
    "    print(f\"Example train data (first 5 rows of first file):\\n{np.ndarray(train_raw_data[0][:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Normalization (Standardization)\n",
    "\n",
    "We fit the `StandardScaler` *only* on the concatenated training data to calculate its mean and standard deviation. These same parameters are then used to transform the training, validation, and test sets to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Normalizing Data ---\n",
      "Scaler fitted. Mean: [-0.01273254 -0.7045118  -0.09500277 -0.6085865   1.9256511  -0.28996933], Std: [ 0.40913334  0.59208745  0.48417    39.229504   30.267822   25.110033  ]\n",
      "Example normalized train data (first 5 rows of first file):\n",
      "[[ 0.19343032  0.00893968 -0.60250735 -0.01249178 -1.0799379  -0.84406126]\n",
      " [ 0.17433508  0.04192678 -0.52989596 -0.06694647 -1.2089942  -0.7322487 ]\n",
      " [ 0.04066838  0.02873194 -0.4572846  -0.11517777 -1.2997367  -0.64717394]\n",
      " [-0.06435545  0.00234226 -0.4250129  -0.14629474 -1.3682979  -0.54022276]\n",
      " [-0.16937926 -0.07022937 -0.31206185 -0.1836351  -1.42476    -0.45271727]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 3: Normalizing Data ---\")\n",
    "\n",
    "# Concatenate all training data files to fit the scaler\n",
    "full_train_data_for_scaler = np.concatenate(train_raw_data, axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(full_train_data_for_scaler)\n",
    "\n",
    "print(f\"Scaler fitted. Mean: {scaler.mean}, Std: {scaler.std}\")\n",
    "\n",
    "# Apply the transformation to each individual data file in all splits\n",
    "train_norm_data = [scaler.transform(d) for d in train_raw_data]\n",
    "val_norm_data = [scaler.transform(d) for d in val_raw_data]\n",
    "test_norm_data = [scaler.transform(d) for d in test_raw_data]\n",
    "\n",
    "if train_norm_data:\n",
    "    print(f\"Example normalized train data (first 5 rows of first file):\\n{train_norm_data[0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Segmentation\n",
    "\n",
    "The normalized data from each split is then segmented into fixed-size, overlapping windows. Each segment inherits the `is_fall` label from its original trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Segmenting Data ---\n",
      "Segmented Training Data Shape: (32106, 600, 6), Labels Shape: (32106,)\n",
      "Segmented Validation Data Shape: (4646, 600, 6), Labels Shape: (4646,)\n",
      "Segmented Test Data Shape: (10931, 600, 6), Labels Shape: (10931,)\n",
      "Example of a segmented window (first window, first 5 rows):\n",
      " [[ 0.19343032  0.00893968 -0.60250735 -0.01249178 -1.0799379  -0.84406126]\n",
      " [ 0.17433508  0.04192678 -0.52989596 -0.06694647 -1.2089942  -0.7322487 ]\n",
      " [ 0.04066838  0.02873194 -0.4572846  -0.11517777 -1.2997367  -0.64717394]\n",
      " [-0.06435545  0.00234226 -0.4250129  -0.14629474 -1.3682979  -0.54022276]\n",
      " [-0.16937926 -0.07022937 -0.31206185 -0.1836351  -1.42476    -0.45271727]]\n",
      "Example of a segmented label (first label): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 4: Segmenting Data ---\")\n",
    "\n",
    "# Extract labels corresponding to the order of data files in each split\n",
    "train_labels_list = train_meta['is_fall'].tolist()\n",
    "val_labels_list = val_meta['is_fall'].tolist()\n",
    "test_labels_list = test_meta['is_fall'].tolist()\n",
    "\n",
    "train_X, train_y = segment_dataset(train_norm_data, train_labels_list, WINDOW_SIZE, OVERLAP)\n",
    "val_X, val_y = segment_dataset(val_norm_data, val_labels_list, WINDOW_SIZE, OVERLAP)\n",
    "test_X, test_y = segment_dataset(test_norm_data, test_labels_list, WINDOW_SIZE, OVERLAP)\n",
    "\n",
    "print(f\"Segmented Training Data Shape: {train_X.shape}, Labels Shape: {train_y.shape}\")\n",
    "print(f\"Segmented Validation Data Shape: {val_X.shape}, Labels Shape: {val_y.shape}\")\n",
    "print(f\"Segmented Test Data Shape: {test_X.shape}, Labels Shape: {test_y.shape}\")\n",
    "\n",
    "print(\"Example of a segmented window (first window, first 5 rows):\\n\", train_X[0, :5, :])\n",
    "print(\"Example of a segmented label (first label):\", train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Serialization\n",
    "\n",
    "Finally, the fully processed data (segmented and normalized), their labels, the fitted `StandardScaler` object, and the complete metadata DataFrame are saved to disk. This allows for quick loading in subsequent model training or evaluation scripts without re-running the entire preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 5: Saving Processed Data ---\n",
      "Processed data, scaler, and metadata saved to /Users/minhphan/src/Fall-TSAD/data/SisFall/processed\n",
      "Data preprocessing pipeline completed and data saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 5: Saving Processed Data ---\")\n",
    "\n",
    "save_processed_data(\n",
    "    output_dir=PROCESSED_DATA_DIR,\n",
    "    train_data=train_X, train_labels=train_y,\n",
    "    val_data=val_X, val_labels=val_y,\n",
    "    test_data=test_X, test_labels=test_y,\n",
    "    scaler=scaler,\n",
    "    metadata_df=metadata_df\n",
    ")\n",
    "\n",
    "print(\"Data preprocessing pipeline completed and data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Loading Processed Data\n",
    "\n",
    "You can load the saved data using the `load_processed_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optional: Loading Processed Data ---\n",
      "Loaded training data shape: (32106, 600, 6)\n",
      "Loaded scaler mean: [-0.01273254 -0.7045118  -0.09500277 -0.6085865   1.9256511  -0.28996933]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>code</th>\n",
       "      <th>subject</th>\n",
       "      <th>group</th>\n",
       "      <th>trial</th>\n",
       "      <th>is_fall</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D01_SA01_R01.txt</td>\n",
       "      <td>D01</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D02_SA01_R01.txt</td>\n",
       "      <td>D02</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D03_SA01_R01.txt</td>\n",
       "      <td>D03</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D04_SA01_R01.txt</td>\n",
       "      <td>D04</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D05_SA01_R01.txt</td>\n",
       "      <td>D05</td>\n",
       "      <td>SA01</td>\n",
       "      <td>Adult</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/minhphan/src/Fall-TSAD/data/SisFall/raw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename code subject  group trial  is_fall  \\\n",
       "0  D01_SA01_R01.txt  D01    SA01  Adult   R01        0   \n",
       "1  D02_SA01_R01.txt  D02    SA01  Adult   R01        0   \n",
       "2  D03_SA01_R01.txt  D03    SA01  Adult   R01        0   \n",
       "3  D04_SA01_R01.txt  D04    SA01  Adult   R01        0   \n",
       "4  D05_SA01_R01.txt  D05    SA01  Adult   R01        0   \n",
       "\n",
       "                                                path  \n",
       "0  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "1  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "2  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "3  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  \n",
       "4  /Users/minhphan/src/Fall-TSAD/data/SisFall/raw...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Optional: Loading Processed Data ---\")\n",
    "loaded_data = load_processed_data(PROCESSED_DATA_DIR)\n",
    "\n",
    "print(\"Loaded training data shape:\", loaded_data['train_data'].shape)\n",
    "print(\"Loaded scaler mean:\", loaded_data['scaler'].mean)\n",
    "display(loaded_data['metadata_df'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg500-tsad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
